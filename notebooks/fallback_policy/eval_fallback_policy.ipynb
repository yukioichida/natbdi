{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-14T12:08:35.994874Z",
     "start_time": "2024-09-14T12:08:32.356584Z"
    }
   },
   "source": [
    "import argparse\n",
    "\n",
    "import lightning\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, Features, Sequence, Value\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from scienceworld import ScienceWorldEnv\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sources.cl_nli.model import SimCSE\n",
    "from sources.fallback_policy.encoder import HFEncoderModel, CustomSimCSEModel\n",
    "from sources.fallback_policy.model import ContrastiveQNetwork\n",
    "from sources.scienceworld.utils import parse_beliefs, parse_goal\n",
    "\n",
    "lightning.seed_everything(42)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:09:36.778238Z",
     "start_time": "2024-09-14T12:09:35.250328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = 'princeton-nlp/sup-simcse-roberta-base'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "encoder_model = HFEncoderModel(model_name, device='cpu')\n",
    "\n",
    "# 2 blocks + original actions + 2 last actions\n",
    "#checkpoint_file = \"../../checkpoints/sup/version_21/epoch=37-step=190-train_loss_epoch=0.803.ckpt\"\n",
    "\n",
    "# all variations\n",
    "#checkpoint_file = \"../../checkpoints/sup_all/version_0/epoch=15-step=4640-train_loss_epoch=0.806.ckpt\"\n",
    "\n",
    "# 2 blocks\n",
    "checkpoint_file = \"../../checkpoints/sup_all/version_0/epoch=20-step=6090-train_loss_epoch=0.790.ckpt\"\n",
    "\n",
    "# 4 blocks\n",
    "#checkpoint_file = \"../../checkpoints/sup_all/version_1/epoch=34-step=10150-train_loss_epoch=0.762.ckpt\"\n",
    "\n",
    "#checkpoint_file = \"../../checkpoints/sup_all/version_4/epoch=29-step=4350-train_loss_epoch=1.256.ckpt\"\n",
    "#checkpoint_file = \"../../checkpoints/sup_all/version_4/epoch=35-step=5220-train_loss_epoch=1.252.ckpt\"\n",
    "checkpoint_file = \"../../checkpoints/sup_all/version_10/epoch=46-step=6815-train_loss_epoch=1.226.ckpt\"\n",
    "\n",
    "model = ContrastiveQNetwork.load_from_checkpoint(checkpoint_file, encoder_model=encoder_model)\n",
    "model = model.to('cpu').eval()"
   ],
   "id": "3c112c121448d43",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:10:32.285219Z",
     "start_time": "2024-09-14T12:10:32.114270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "belief_base_a = ['you see a door', \"you see a cupboard, the cupboard is closed\", \"your goal is to boil water\", \"you focused on water\"]\n",
    "belief_base_b = ['you see a door', \"you see a a door, the door is open\", \"your goal is to boil gallium\", \"you focused on water\"]\n",
    "\n",
    "\n",
    "def encode_belief_base(belief_base: list[str]):\n",
    "    belief_base_emb = model.encoder_model.encode_batch(belief_base,\n",
    "                                                       max_size=len(belief_base),\n",
    "                                                       include_cls=True)\n",
    "    encoded_belief_base, attention = model.belief_base_encoder(belief_base_emb, [len(belief_base) + 1], )\n",
    "    return encoded_belief_base, attention\n",
    "\n",
    "\n",
    "emb_a, a = encode_belief_base(belief_base_a)\n",
    "emb_b, b = encode_belief_base(belief_base_b)\n",
    "\n",
    "sim = torch.nn.functional.cosine_similarity(emb_a, emb_b, dim=1)\n",
    "sim.item()"
   ],
   "id": "c6d0c48a8e98a1d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8149359822273254"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T00:22:23.120899Z",
     "start_time": "2024-09-14T00:22:20.766169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "simcse = SimCSE.load_from_checkpoint('/opt/models/simcse_default/version_0/v0-epoch=4-step=18304-val_nli_loss=0.658-train_loss=0.551.ckpt')\n",
    "\n",
    "encoder = CustomSimCSEModel(simcse)\n",
    "\n",
    "model = ContrastiveQNetwork.load_from_checkpoint(checkpoint_file, encoder_model=encoder)\n",
    "\n",
    "\n",
    "belief_base_a = [\"you see a door to the workshop\", \"you see a cupboard, the cupboard is closed\"]\n",
    "belief_base_b = [\"you see a door to the kitchen\", \"you see a cupboard, the cupboard is open\"]\n",
    "\n",
    "\n",
    "def encode_belief_base(belief_base: list[str]):\n",
    "    belief_base_emb = model.encoder_model.encode_batch(belief_base,\n",
    "                                                       max_size=len(belief_base)+1,\n",
    "                                                       include_cls=True)\n",
    "    encoded_belief_base, attention = model.belief_base_encoder(belief_base_emb, [len(belief_base)+1], )\n",
    "    return encoded_belief_base, attention\n",
    "\n",
    "\n",
    "emb_a, a = encode_belief_base(belief_base_a)\n",
    "emb_b, b = encode_belief_base(belief_base_b)\n",
    "\n",
    "sim = torch.nn.functional.cosine_similarity(emb_a, emb_b, dim=1)\n",
    "sim"
   ],
   "id": "5a3963f7f0d9772f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.3850], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T12:30:29.350473Z",
     "start_time": "2024-09-14T12:30:29.269524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emb_a = encoder_model.encode(belief_base_a)\n",
    "emb_a.size()"
   ],
   "id": "b6747640c1ebd9e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d00b274bc7de6b6a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
