{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-19T01:13:15.095619Z",
     "start_time": "2024-08-19T01:13:13.142952Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "from sources.cl_nli.model import SimCSE\n",
    "from sources.fallback_policy.replay import ReplayMemory, Transition\n",
    "from sources.scienceworld import parse_beliefs"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reading goldpath trajectories",
   "id": "43b359c162afc26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T01:13:15.102810Z",
     "start_time": "2024-08-19T01:13:15.097097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "goldpath_file = \"/opt/data/scienceworld-goldpaths/goldsequences-0.json\"\n",
    "\n",
    "with open(goldpath_file) as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "json_data = json_data['0']\n",
    "\n",
    "json_data.keys()"
   ],
   "id": "665684dbb9595f29",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['taskIdx', 'taskName', 'goldActionSequences'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T01:13:18.432971Z",
     "start_time": "2024-08-19T01:13:15.103930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ckpt = \"/opt/models/simcse_default/version_0/v0-epoch=4-step=18304-val_nli_loss=0.658-train_loss=0.551.ckpt\"\n",
    "\n",
    "model: SimCSE = SimCSE.load_from_checkpoint(ckpt).eval()\n",
    "hf_model_name = model.hparams['hf_model_name']\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model_name)"
   ],
   "id": "9e98b425dbabce41",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ichida/miniconda3/envs/default_env/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T01:13:19.265713Z",
     "start_time": "2024-08-19T01:13:18.434895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "simcse_tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/sup-simcse-roberta-base\")\n",
    "simcse_model = AutoModel.from_pretrained(\"princeton-nlp/sup-simcse-roberta-base\").eval().to('cuda')"
   ],
   "id": "3465d8f449d64f6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create memory buffer",
   "id": "b8bd533771827901"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T01:13:19.271686Z",
     "start_time": "2024-08-19T01:13:19.266768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode_custom(texts: list[str], max_size: int = 25, include_cls: bool = True) -> torch.Tensor:\n",
    "    if include_cls:\n",
    "        cls_token = tokenizer.cls_token\n",
    "        texts = [cls_token] + texts\n",
    "    pad_size = max_size - len(texts)\n",
    "    padding = [tokenizer.pad_token for _ in range(pad_size)]\n",
    "    texts = texts + padding\n",
    "    tokenized_text = tokenizer(texts, padding='longest', truncation=True,\n",
    "                               return_tensors='pt').to(model.device)\n",
    "    embeddings = model.encode(tokenized_text).detach().unsqueeze(0)  # batch axis\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def encode_simcse(texts: list[str], max_size: int = 25, include_cls: bool = True) -> torch.Tensor:\n",
    "    with torch.no_grad():\n",
    "        if include_cls:\n",
    "            cls_token = simcse_tokenizer.cls_token\n",
    "            texts = [cls_token] + texts\n",
    "        pad_size = max_size - len(texts)\n",
    "        padding = [simcse_tokenizer.pad_token for _ in range(pad_size)]\n",
    "        texts = texts + padding\n",
    "        tokenized_text = simcse_tokenizer(texts, padding='longest', truncation=True,\n",
    "                                          return_tensors='pt').to('cuda')\n",
    "        embeddings = simcse_model(**tokenized_text).pooler_output.unsqueeze(0)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "def encode(texts: list[str], max_size: int = 25, include_cls: bool = True) -> torch.Tensor:\n",
    "    return encode_custom(texts, max_size, include_cls)"
   ],
   "id": "7c004c5d2c3bf248",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T01:18:02.992047Z",
     "start_time": "2024-08-19T01:17:59.977583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gold_sequence = json_data['goldActionSequences'][0]['path']\n",
    "\n",
    "goal = json_data['goldActionSequences'][0]['taskDescription'].split('.')[0]\n",
    "variation_idx = json_data['goldActionSequences'][0]['variationIdx']\n",
    "print(f\"Goal: {goal} - variation {variation_idx}\")\n",
    "\n",
    "all_lens = []\n",
    "\n",
    "trajectories_bdi = []\n",
    "\n",
    "memory_buffer = ReplayMemory(1000)\n",
    "\n",
    "last_reward = 0\n",
    "observation = \"\"\n",
    "for i, trajectory in enumerate(gold_sequence):\n",
    "    look_around = trajectory['freelook']\n",
    "    inventory = trajectory['inventory']\n",
    "    belief_base = parse_beliefs(observation=observation, look=look_around, inventory=inventory)\n",
    "\n",
    "    next_trajectory = gold_sequence[i + 1]\n",
    "    next_belief_base = parse_beliefs(observation=next_trajectory['observation'],\n",
    "                                     look=next_trajectory['freelook'],\n",
    "                                     inventory=next_trajectory['inventory'])\n",
    "\n",
    "    reward = float(trajectory['score']) - last_reward\n",
    "    last_reward = float(trajectory['score'])\n",
    "    is_done = trajectory['isCompleted']\n",
    "    if is_done == 'true':\n",
    "        next_state = \"\"\n",
    "        print(\"finish\")\n",
    "        break\n",
    "        # ou break de repente aqui\n",
    "    if trajectory['action'] != 'look around':\n",
    "        memory_buffer.push(\n",
    "                Transition(\n",
    "                        belief_base=encode(belief_base + [goal], include_cls=False),\n",
    "                        num_beliefs=len(belief_base) + 1,  # including goal\n",
    "                        action=encode([trajectory['action']], max_size=1, include_cls=False),\n",
    "                        next_belief_base=encode(next_belief_base + [goal]),\n",
    "                        num_next_beliefs=len(next_belief_base) + 1,\n",
    "                        next_action=encode([next_trajectory['action']], max_size=1, include_cls=False),\n",
    "                        reward=reward,\n",
    "                        done=True if is_done == 'true' else False\n",
    "                )\n",
    "        )\n",
    "    observation = trajectory['observation']\n",
    "\n",
    "    #print(f\"Step {i} - reward: {reward:.3f} - is_done: {is_done}  - action: {trajectory['action']}\")"
   ],
   "id": "585ca7affeca7d46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal: Your task is to boil water - variation 0\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train q-network using annotated trajectories",
   "id": "c326011ec0529219"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T01:19:17.374107Z",
     "start_time": "2024-08-19T01:19:17.348551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sources.fallback_policy.model import SimpleQNetwork, QNetwork\n",
    "\n",
    "#network = QNetwork(768, 768, n_blocks=3)\n",
    "network = SimpleQNetwork(768, 768, 1)\n",
    "network = network.to('cuda')\n",
    "network.train()\n",
    "\n",
    "num_parameters = sum(p.numel() for p in network.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters: {num_parameters}\")\n",
    "network"
   ],
   "id": "19ec2323278a0b35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 1771008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleQNetwork(\n",
       "  (belief_base_encoder): ModuleList(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (hidden): Linear(in_features=1536, out_features=768, bias=False)\n",
       "  (q_value_layer): Linear(in_features=768, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T01:21:50.539833Z",
     "start_time": "2024-08-19T01:21:44.939782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# q-learning \n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "def contrastive_loss(belief_base_emb, num_belief_emb, action_emb):\n",
    "    # USING CONTRASTIVE LOSS  (cross entropy) does not work well\n",
    "    # maybe because we did not need to use a softmax function at the top of network to predict q-values\n",
    "    batch_size, _, _ = belief_base_emb.size()\n",
    "\n",
    "    belief_q_values = []\n",
    "    for belief_idx in range(BATCH_SIZE):\n",
    "        c_belief_base = belief_base_emb[belief_idx, :, :].unsqueeze(0)\n",
    "        c_belief_base = c_belief_base.repeat(batch_size, 1, 1)\n",
    "        q_values = network(belief_base=c_belief_base,\n",
    "                           belief_base_sizes=[num_belief_emb[belief_idx] for _ in range(batch_size)],\n",
    "                           action_tensors=action_emb)\n",
    "        belief_q_values.append(q_values.squeeze(0))\n",
    "\n",
    "    all_q_values = torch.cat(belief_q_values, dim=-1)\n",
    "    labels = torch.zeros_like(all_q_values).to('cuda')\n",
    "    labels = labels.fill_diagonal_(1)\n",
    "    all_q_values = all_q_values.view(batch_size * batch_size, 1)\n",
    "    labels = labels.view(batch_size * batch_size, 1)\n",
    "    #return F.mse_loss(all_q_values, labels)\n",
    "    return F.smooth_l1_loss(all_q_values, labels)\n",
    "\n",
    "\n",
    "for epoch in range(300):\n",
    "    batch = memory_buffer.sample(BATCH_SIZE)\n",
    "    belief_base_emb = torch.cat([b.belief_base for b in batch], dim=0)\n",
    "    batch_size, _, belief_dim = belief_base_emb.size()\n",
    "    num_belief_emb = [b.num_beliefs for b in batch]\n",
    "    actions = torch.cat([b.action for b in batch]).squeeze(1)  # removing mid axis [bs, ?, a_dim] -> [bs, a_dim]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = contrastive_loss(belief_base_emb, num_belief_emb, actions)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"epoch {epoch} - loss {loss.item(): .4f}\")\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #break\n",
    "    #nn.utils.clip_grad_norm_(network.parameters(), 1.)\n",
    "\n",
    "print(f\"epoch {epoch} - loss {loss.item(): .4f}\")\n",
    "# simple network 0.0288"
   ],
   "id": "76073dcf3fff52a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - loss  0.0233\n",
      "epoch 100 - loss  0.0219\n",
      "epoch 200 - loss  0.0218\n",
      "epoch 299 - loss  0.0219\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T01:23:03.877384Z",
     "start_time": "2024-08-19T01:23:03.871313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "turn = 5\n",
    "expected_action = gold_sequence[turn]['action']\n",
    "print(expected_action)\n",
    "annotated_belief_base = parse_beliefs(observation=gold_sequence[turn - 1]['observation'],\n",
    "                                      look=gold_sequence[turn]['freelook'],\n",
    "                                      inventory=gold_sequence[turn]['inventory']) + [goal]\n",
    "#annotated_belief_base = ['This room is called the kitchen', 'You see a anchor', 'you see a metal pot'] + [goal]\n",
    "print(len(annotated_belief_base))\n",
    "annotated_belief_base"
   ],
   "id": "4d8219195d3e7a1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open cupboard\n",
      "23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['This room is called the kitchen.',\n",
       " 'You see a substance called soap',\n",
       " 'You see a painting',\n",
       " 'You see a counter. On the counter is: a bowl (containing a banana, a potato, a red apple, an orange), a drawer.',\n",
       " 'You see a sink, which is turned off. In the sink is: nothing.',\n",
       " 'You see a table. On the table is: a glass cup (containing nothing).',\n",
       " 'You see a chair. On the chair is: nothing.',\n",
       " 'You see a freezer. The freezer door is closed.',\n",
       " 'You see a lighter',\n",
       " 'You see a stopwatch, which is deactivated.',\n",
       " 'You see a fridge. The fridge door is closed.',\n",
       " 'You see a substance called air',\n",
       " 'You see a cupboard. The cupboard door is closed.',\n",
       " 'You see a oven, which is turned off. The oven door is closed.',\n",
       " 'You see a glass jar (containing a substance called sodium chloride)',\n",
       " 'You see the agent',\n",
       " 'You see a stove, which is turned off. On the stove is: nothing.',\n",
       " 'A door to the outside (that is open)',\n",
       " 'A door to the bathroom (that is open)',\n",
       " 'A door to the hallway (that is open)',\n",
       " 'In your inventory, you see: a thermometer, currently reading a temperature of 10 degrees celsius an orange ',\n",
       " 'You move the thermometer to the inventory.',\n",
       " 'Your task is to boil water']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T01:23:16.292756Z",
     "start_time": "2024-08-19T01:23:16.224097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoded_belief_base = encode(annotated_belief_base, max_size=len(annotated_belief_base) + 1, include_cls=False)\n",
    "print(encoded_belief_base.size())\n",
    "#candidate_actions = info['valid']\n",
    "candidate_actions = ['focus on bedroom door', 'open door to kitchen', 'go to kitchen', 'deactivate sink'] + [\n",
    "        expected_action]\n",
    "encoded_actions = encode(candidate_actions, include_cls=False, max_size=len(candidate_actions))\n",
    "encoded_actions = encoded_actions.squeeze(0)\n",
    "print(\"encoded_actions: \", encoded_actions.size())\n",
    "num_actions, action_dim = encoded_actions.size()\n",
    "repeat_encoded_belief_base = encoded_belief_base.repeat(num_actions, 1, 1)\n",
    "q_values = network(belief_base=repeat_encoded_belief_base,\n",
    "                   belief_base_sizes=[len(annotated_belief_base) + 1 for _ in range(num_actions)],\n",
    "                   action_tensors=encoded_actions)\n",
    "print(q_values.size())\n",
    "\n",
    "values, idxs = torch.sort(q_values.squeeze(1), descending=True)\n",
    "for i, idx in enumerate(idxs[:5]):\n",
    "    print(f\"act {candidate_actions[idx]} - q_value: {values[i]:.3f}\")"
   ],
   "id": "ce878dffffd298de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 768])\n",
      "encoded_actions:  torch.Size([5, 768])\n",
      "torch.Size([5, 1])\n",
      "act open cupboard - q_value: 0.405\n",
      "act deactivate sink - q_value: 0.055\n",
      "act open door to kitchen - q_value: 0.008\n",
      "act go to kitchen - q_value: -0.016\n",
      "act focus on bedroom door - q_value: -0.084\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T01:22:29.382771Z",
     "start_time": "2024-08-19T01:22:29.380351Z"
    }
   },
   "cell_type": "code",
   "source": "# try to infer context by the similarity between beliefs and the action",
   "id": "888288e2d54e0046",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T01:22:29.620493Z",
     "start_time": "2024-08-19T01:22:29.615694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "action_idx = q_values.squeeze(1).argmax()\n",
    "action = candidate_actions[action_idx]\n",
    "action, encoded_actions[action_idx, :].size(), action_idx"
   ],
   "id": "cc745f0a2e26d1cc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('go to kitchen', torch.Size([768]), tensor(2, device='cuda:0'))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T01:13:46.009860Z",
     "start_time": "2024-08-19T01:13:46.005439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bb = encoded_belief_base.squeeze(0)\n",
    "num_beliefs, belief_dim = bb.size()\n",
    "emb_action = encoded_actions[action_idx, :].unsqueeze(0).repeat(num_beliefs, 1)\n",
    "emb_action.size(), bb.size()"
   ],
   "id": "7ee8adaf7fb9e491",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24, 768]), torch.Size([24, 768]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T01:13:46.019009Z",
     "start_time": "2024-08-19T01:13:46.010977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "similarity = nn.CosineSimilarity(dim=-1)(emb_action, bb)\n",
    "#similarity = similarity[similarity > 0.5]\n",
    "top_similarity, idx = torch.sort(similarity, descending=True)\n",
    "top_similarity, idx\n"
   ],
   "id": "f54ed1d2f0e54fa7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.7226,  0.4007,  0.3132,  0.2898,  0.2477,  0.2329,  0.1887,  0.1622,\n",
       "          0.1534,  0.1269,  0.1231,  0.0429,  0.0402,  0.0185,  0.0138,  0.0064,\n",
       "         -0.0046, -0.0082, -0.0153, -0.0256, -0.0520, -0.1454, -0.1789, -0.2692],\n",
       "        device='cuda:0'),\n",
       " tensor([ 4, 13, 20, 16,  9,  7, 10, 17, 11,  8,  6, 22, 12, 23, 18, 19, 21,  2,\n",
       "          5, 14, 15,  1,  3,  0], device='cuda:0'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T01:13:46.061593Z",
     "start_time": "2024-08-19T01:13:46.059817Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a1d70f39c5ce9db6",
   "outputs": [],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
