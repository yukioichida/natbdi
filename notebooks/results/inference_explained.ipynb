{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-05T19:01:10.180800230Z",
     "start_time": "2023-10-05T19:01:10.166228092Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build a matrix of sentence combinations\n",
    "\n",
    "In the BDI architecture, in order to select a plan to execute in the environment, the agent needs to check whether its context is entailed by the agent's belief base.\n",
    "Formally, given a set of beliefs $B$ and a set of contexts $C$, the expression $\\bigwedge_{c_i \\in C}\\bigvee_{b_j \\in \\mathcal{B}} b_j \\models c_i$ must be true.\n",
    "\n",
    "Since our work deals in natural language representations, we create a matrix with all combinations between all sentences contained in the belief base with all plan context sentences.\n",
    "Specifically, given a set of natural language sentences representing the belief base $B$ and another sentence set representing the context $C$, the inference operation executes the cartesian product $C \\times B = \\{(c, b) | c \\in C \\wedge b \\in B\\}$ to formulate all pairs of $(c, b)$ as input of the natural language inference model.\n",
    "In our approach, we follow the $\\bigwedge_{c_i \\in C}\\bigvee_{b_j \\in \\mathcal{B}} b_j \\models c_i$ expression and generate the cartesian product as context-wise."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinations = 6\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('you are in the kitchen', 'This room is called the kitchen.'),\n ('you are in the kitchen',\n  'You see a cupboard. The cupboard door is closed.'),\n ('you are in the kitchen', 'You see a freezer. The freezer door is closed.'),\n ('you see a closed cupboard', 'This room is called the kitchen.'),\n ('you see a closed cupboard',\n  'You see a cupboard. The cupboard door is closed.'),\n ('you see a closed cupboard',\n  'You see a freezer. The freezer door is closed.')]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beliefs = ['This room is called the kitchen.', 'You see a cupboard. The cupboard door is closed.', 'You see a freezer. The freezer door is closed.']\n",
    "\n",
    "context = ['you are in the kitchen', 'you see a closed cupboard']\n",
    "\n",
    "num_ctx_statements = len(context)\n",
    "num_beliefs = len(beliefs)\n",
    "#\n",
    "\n",
    "all_sentence_pairs = list(itertools.product(context, beliefs))\n",
    "all_sentence_pairs.sort(key=lambda x: x[0])\n",
    "print(f\"Combinations = {len(all_sentence_pairs)}\")\n",
    "all_sentence_pairs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T19:01:10.589780331Z",
     "start_time": "2023-10-05T19:01:10.582532530Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n",
      "{'contradiction': 2, 'entailment': 0, 'neutral': 1}\n",
      "Model loaded 1.657421588897705 - model cpu\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Loading Model\")\n",
    "\n",
    "max_length = 256\n",
    "\n",
    "hg_model_hub_name = \"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
    "#hg_model_hub_name = \"alisawuffles/roberta-large-wanli\"\n",
    "hg_model_hub_name = \"gchhablani/bert-base-cased-finetuned-mnli\"\n",
    "config = AutoConfig.from_pretrained(hg_model_hub_name)\n",
    "\n",
    "\n",
    "config = AutoConfig.from_pretrained(hg_model_hub_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(hg_model_hub_name)\n",
    "\n",
    "print(config.label2id)\n",
    "entailment_idx = config.label2id['entailment']\n",
    "\n",
    "\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(hg_model_hub_name)\n",
    "nli_model.to(device)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Model loaded {end - start} - model {nli_model.device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T19:03:26.966812718Z",
     "start_time": "2023-10-05T19:03:25.308545766Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Manipulating vectors resulted from LLM\n",
    "The next step is the application of natural language inference model for each sentence pair contained in the cartesian product $C \\times B$.\n",
    "Given a sentence pair $p$ and the NLI model represented by the function $nli$, we generate a matrix $I = \\{nli(p) | p \\in C \\times B\\}$ with all inference results.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([0, 1, 2, 1, 0, 1]),\n tensor([[9.5543e-01, 4.2699e-02, 1.8752e-03],\n         [3.3027e-03, 9.9517e-01, 1.5271e-03],\n         [2.5197e-04, 3.0294e-02, 9.6945e-01],\n         [5.5346e-03, 9.9284e-01, 1.6254e-03],\n         [9.4714e-01, 5.1388e-02, 1.4737e-03],\n         [2.7999e-03, 6.0283e-01, 3.9437e-01]], grad_fn=<SoftmaxBackward0>))"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert into a matrix representation\n",
    "tokenized_input_seq_pair = tokenizer.batch_encode_plus(all_sentence_pairs,\n",
    "                                                                    return_token_type_ids=True, truncation=True,\n",
    "                                                                    padding=True)\n",
    "\n",
    "input_ids = torch.tensor(tokenized_input_seq_pair['input_ids'], device=device).long()\n",
    "token_type_ids = torch.tensor(tokenized_input_seq_pair['token_type_ids'], device=device).long()\n",
    "attention_mask = torch.tensor(tokenized_input_seq_pair['attention_mask'], device=device).long()\n",
    "\n",
    "# predicting NLI results\n",
    "outputs = nli_model(input_ids,\n",
    "                   attention_mask=attention_mask,\n",
    "                   token_type_ids=token_type_ids,\n",
    "                   labels=None)\n",
    "\n",
    "nli_result = outputs[0]\n",
    "probs = torch.softmax(nli_result, dim=1)\n",
    "predicted_classes = probs.argmax(-1)\n",
    "predicted_classes, probs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T19:03:30.566229049Z",
     "start_time": "2023-10-05T19:03:30.483919978Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Slicing matrix\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c0 x B = Slice tensor([ True, False, False])\n",
      "c1 x B = Slice tensor([False,  True, False])\n",
      "OR operation\n"
     ]
    },
    {
     "data": {
      "text/plain": "[tensor([True]), tensor([True])]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: explicar quais linhas representam os contextos\n",
    "\n",
    "# True when a c_n is entailed by b_n\n",
    "entailment_mask = torch.where(predicted_classes == entailment_idx, True, False)\n",
    "# [B,c1:B,c2:...:B,cn]\n",
    "slice_idx = []\n",
    "idx = 0\n",
    "for i in range(num_ctx_statements):  # [c1, ..., cn]\n",
    "    slice = entailment_mask[idx:(idx + num_beliefs)]\n",
    "    slice_idx.append(slice)\n",
    "    print(f\"c{i} x B = Slice {slice}\")\n",
    "    idx = num_beliefs\n",
    "\n",
    "# True if ANY context comparation is ENTAILED by an belief in belief base (OR)\n",
    "context_or = [torch.where(c == entailment_idx, True, False).any().unsqueeze(0) for c in slice_idx]\n",
    "print(\"OR operation\")\n",
    "context_or"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T19:03:33.190413355Z",
     "start_time": "2023-10-05T19:03:33.164731125Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(True)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_tensor = torch.concatenate(context_or)  # at least one belief should entail a context (OR)\n",
    "and_result = or_tensor.all()  # all context must be entailed by the belief base (AND)\n",
    "and_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T19:03:34.365154461Z",
     "start_time": "2023-10-05T19:03:34.351142249Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: This room is called the kitchen.\n",
      "H: you are in the kitchen\n",
      "Entailment: True\n",
      "P: You see a cupboard. The cupboard door is closed.\n",
      "H: you are in the kitchen\n",
      "Entailment: False\n",
      "P: You see a freezer. The freezer door is closed.\n",
      "H: you are in the kitchen\n",
      "Entailment: False\n",
      "P: This room is called the kitchen.\n",
      "H: you see a closed cupboard\n",
      "Entailment: False\n",
      "P: You see a cupboard. The cupboard door is closed.\n",
      "H: you see a closed cupboard\n",
      "Entailment: True\n",
      "P: You see a freezer. The freezer door is closed.\n",
      "H: you see a closed cupboard\n",
      "Entailment: False\n"
     ]
    }
   ],
   "source": [
    "for pair, predict in zip(all_sentence_pairs, predicted_classes):\n",
    "    print(f\"P: {pair[1]}\")\n",
    "    print(f\"H: {pair[0]}\")\n",
    "    print(f\"Entailment: {predict == entailment_idx}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T18:45:29.642604600Z",
     "start_time": "2023-10-04T18:45:29.637474277Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "690"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../results/v2-minilm/results_nli_melt.csv\") # lm failure before achieve others actions\n",
    "len(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T21:14:50.172887705Z",
     "start_time": "2023-10-04T21:14:50.164914370Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "690"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.drop_duplicates())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T21:14:51.578789409Z",
     "start_time": "2023-10-04T21:14:51.569896028Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
