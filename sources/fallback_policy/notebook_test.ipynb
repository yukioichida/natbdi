{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-06T11:01:15.209713Z",
     "start_time": "2024-09-06T11:01:13.782091Z"
    }
   },
   "source": [
    "import torch\n",
    "import json"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T11:01:15.216022Z",
     "start_time": "2024-09-06T11:01:15.211013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "goldpath_file = \"/opt/data/scienceworld-goldpaths/goldsequences-0.json\"\n",
    "with open(goldpath_file) as f:\n",
    "    data = json.load(f)\n",
    "json_data = data['0']\n",
    "\n",
    "gold_sequence = json_data['goldActionSequences'][0]['path']\n",
    "goal = json_data['goldActionSequences'][0]['taskDescription'].split('.')[0]\n",
    "variation_idx = json_data['goldActionSequences'][0]['variationIdx']\n",
    "print(f\"Goal: {goal} - variation {variation_idx}\")\n",
    "\n",
    "last_reward = 0\n",
    "use_cls = True\n",
    "observation = \"\"\n",
    "all_trajectories = []\n",
    "for i, trajectory in enumerate(gold_sequence):\n",
    "    look_around = trajectory['freelook']\n",
    "    inventory = trajectory['inventory']\n",
    "    full_state = look_around + inventory + trajectory['observation']\n",
    "    print(f\"Step {i}: {trajectory['action']} - num tokens {len(full_state)}\")"
   ],
   "id": "3d4f14020244416a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal: Your task is to boil water - variation 0\n",
      "Step 0: look around - num tokens 738\n",
      "Step 1: open door to kitchen - num tokens 414\n",
      "Step 2: go to kitchen - num tokens 413\n",
      "Step 3: look around - num tokens 1884\n",
      "Step 4: pick up thermometer - num tokens 1004\n",
      "Step 5: open cupboard - num tokens 987\n",
      "Step 6: pick up metal pot - num tokens 1131\n",
      "Step 7: look around - num tokens 2038\n",
      "Step 8: move metal pot to sink - num tokens 1126\n",
      "Step 9: activate sink - num tokens 1108\n",
      "Step 10: deactivate sink - num tokens 1126\n",
      "Step 11: pick up metal pot - num tokens 1139\n",
      "Step 12: focus on substance in metal pot - num tokens 1131\n",
      "Step 13: pour metal pot into metal pot - num tokens 1145\n",
      "Step 14: pick up metal pot - num tokens 1148\n",
      "Step 15: move metal pot to stove - num tokens 1144\n",
      "Step 16: activate stove - num tokens 1126\n",
      "Step 17: examine substance in metal pot - num tokens 1122\n",
      "Step 18: use thermometer in inventory on substance in metal pot - num tokens 1158\n",
      "Step 19: examine substance in metal pot - num tokens 1122\n",
      "Step 20: use thermometer in inventory on substance in metal pot - num tokens 1158\n",
      "Step 21: examine substance in metal pot - num tokens 1122\n",
      "Step 22: use thermometer in inventory on substance in metal pot - num tokens 1158\n",
      "Step 23: examine substance in metal pot - num tokens 1122\n",
      "Step 24: use thermometer in inventory on substance in metal pot - num tokens 1158\n",
      "Step 25: examine substance in metal pot - num tokens 1122\n",
      "Step 26: use thermometer in inventory on substance in metal pot - num tokens 1158\n",
      "Step 27: examine substance in metal pot - num tokens 1122\n",
      "Step 28: use thermometer in inventory on substance in metal pot - num tokens 1158\n",
      "Step 29: examine substance in metal pot - num tokens 1122\n",
      "Step 30: use thermometer in inventory on substance in metal pot - num tokens 1158\n",
      "Step 31: examine substance in metal pot - num tokens 1122\n",
      "Step 32: use thermometer in inventory on substance in metal pot - num tokens 1158\n",
      "Step 33: examine substance in metal pot - num tokens 1122\n",
      "Step 34: use thermometer in inventory on substance in metal pot - num tokens 1158\n",
      "Step 35: examine substance in metal pot - num tokens 1122\n",
      "Step 36: use thermometer in inventory on substance in metal pot - num tokens 1158\n",
      "Step 37: examine steam - num tokens 1122\n",
      "Step 38: use thermometer in inventory on steam - num tokens 1159\n",
      "Step 39: wait1 - num tokens 1134\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T11:38:31.969856Z",
     "start_time": "2024-09-03T11:38:30.580428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Import our models. The package will take care of downloading the models automatically\n",
    "model_name = \"princeton-nlp/sup-simcse-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize input texts\n",
    "texts = [\n",
    "    \"focus on substance in metal pot\",\n",
    "    \"focus on metal pot\",\n",
    "    \"pour metal pot into metal pot\"\n",
    "]\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Get the embeddings\n",
    "with torch.no_grad():\n",
    "    embeddings = model(**inputs, output_hidden_states=True, return_dict=True).pooler_output\n",
    "print(embeddings.size())\n",
    "# Calculate cosine similarities\n",
    "# Cosine similarities are in [-1, 1]. Higher means more similar\n",
    "cosine_sim_0_1 = 1 - cosine(embeddings[0], embeddings[1])\n",
    "cosine_sim_0_2 = 1 - cosine(embeddings[0], embeddings[2])\n",
    "\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[1], cosine_sim_0_1))\n",
    "print(\"Cosine similarity between \\\"%s\\\" and \\\"%s\\\" is: %.3f\" % (texts[0], texts[2], cosine_sim_0_2))\n"
   ],
   "id": "818af5e0271479d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1024])\n",
      "Cosine similarity between \"focus on substance in metal pot\" and \"focus on metal pot\" is: 0.934\n",
      "Cosine similarity between \"focus on substance in metal pot\" and \"pour metal pot into metal pot\" is: 0.763\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T11:10:50.875785Z",
     "start_time": "2024-09-03T11:10:50.871357Z"
    }
   },
   "cell_type": "code",
   "source": "trajectory['inventory']",
   "id": "3c27f6a5091ab20c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In your inventory, you see:\\n\\ta thermometer, currently reading a temperature of 10 degrees celsius\\n\\tan orange\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T11:13:26.004268Z",
     "start_time": "2024-09-03T11:13:26.000236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inv_fragments = trajectory['inventory'].split(\"\\n\")\n",
    "inv_fragments = [i.replace(\"\\t\", \"\") for i in inv_fragments if len(i) > 0]\n",
    "inv_preamble = inv_fragments[0]\n",
    "inv_fragments = [f\"{inv_preamble} {i}\" for i in inv_fragments[1:]]\n",
    "inv_fragments"
   ],
   "id": "16ac514b6b6207ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In your inventory, you see: a thermometer, currently reading a temperature of 10 degrees celsius',\n",
       " 'In your inventory, you see: an orange']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T12:31:55.597969Z",
     "start_time": "2024-09-03T12:31:51.968036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "from sentence_transformers.quantization import quantize_embeddings\n",
    "\n",
    "# 1. Specify preffered dimensions\n",
    "dimensions = 512\n",
    "\n",
    "# 2. load model\n",
    "model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\", truncate_dim=dimensions)\n",
    "\n",
    "# For retrieval you need to pass this prompt.\n",
    "query = \"focus on substance in metal pot\"\n",
    "\n",
    "docs = [\n",
    "    query,\n",
    "    \"focus on metal pot\",\n",
    "    \"pour metal pot into metal pot\"\n",
    "]\n",
    "\n",
    "# 2. Encode\n",
    "embeddings = model.encode(docs)\n",
    "\n",
    "# Optional: Quantize the embeddings\n",
    "binary_embeddings = quantize_embeddings(embeddings, precision=\"uint8\")\n",
    "\n",
    "similarities = cos_sim(binary_embeddings[0], binary_embeddings[1:])\n",
    "print('similarities:', similarities)\n"
   ],
   "id": "777f806ce6769d06",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ichida/miniconda3/envs/default_env/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Computing uint8 quantization buckets based on 3 embeddings. uint8 quantization is more stable with `ranges` calculated from more embeddings or a `calibration_embeddings` that can be used to calculate the buckets.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "linalg.vector_norm: Expected a floating point or complex tensor as input. Got Byte",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[40], line 26\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Optional: Quantize the embeddings\u001B[39;00m\n\u001B[1;32m     24\u001B[0m binary_embeddings \u001B[38;5;241m=\u001B[39m quantize_embeddings(embeddings, precision\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muint8\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 26\u001B[0m similarities \u001B[38;5;241m=\u001B[39m cos_sim(binary_embeddings[\u001B[38;5;241m0\u001B[39m], binary_embeddings[\u001B[38;5;241m1\u001B[39m:])\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msimilarities:\u001B[39m\u001B[38;5;124m'\u001B[39m, similarities)\n",
      "File \u001B[0;32m~/miniconda3/envs/default_env/lib/python3.11/site-packages/sentence_transformers/util.py:95\u001B[0m, in \u001B[0;36mcos_sim\u001B[0;34m(a, b)\u001B[0m\n\u001B[1;32m     92\u001B[0m a \u001B[38;5;241m=\u001B[39m _convert_to_batch_tensor(a)\n\u001B[1;32m     93\u001B[0m b \u001B[38;5;241m=\u001B[39m _convert_to_batch_tensor(b)\n\u001B[0;32m---> 95\u001B[0m a_norm \u001B[38;5;241m=\u001B[39m normalize_embeddings(a)\n\u001B[1;32m     96\u001B[0m b_norm \u001B[38;5;241m=\u001B[39m normalize_embeddings(b)\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mmm(a_norm, b_norm\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[0;32m~/miniconda3/envs/default_env/lib/python3.11/site-packages/sentence_transformers/util.py:263\u001B[0m, in \u001B[0;36mnormalize_embeddings\u001B[0;34m(embeddings)\u001B[0m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnormalize_embeddings\u001B[39m(embeddings: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m    254\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;124;03m    Normalizes the embeddings matrix, so that each sentence embedding has unit length.\u001B[39;00m\n\u001B[1;32m    256\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;124;03m        Tensor: The normalized embeddings matrix.\u001B[39;00m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 263\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mnormalize(embeddings, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/default_env/lib/python3.11/site-packages/torch/nn/functional.py:4780\u001B[0m, in \u001B[0;36mnormalize\u001B[0;34m(input, p, dim, eps, out)\u001B[0m\n\u001B[1;32m   4778\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(normalize, (\u001B[38;5;28minput\u001B[39m, out), \u001B[38;5;28minput\u001B[39m, p\u001B[38;5;241m=\u001B[39mp, dim\u001B[38;5;241m=\u001B[39mdim, eps\u001B[38;5;241m=\u001B[39meps, out\u001B[38;5;241m=\u001B[39mout)\n\u001B[1;32m   4779\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 4780\u001B[0m     denom \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mnorm(p, dim, keepdim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\u001B[38;5;241m.\u001B[39mclamp_min(eps)\u001B[38;5;241m.\u001B[39mexpand_as(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m   4781\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m/\u001B[39m denom\n\u001B[1;32m   4782\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/default_env/lib/python3.11/site-packages/torch/_tensor.py:765\u001B[0m, in \u001B[0;36mTensor.norm\u001B[0;34m(self, p, dim, keepdim, dtype)\u001B[0m\n\u001B[1;32m    761\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    763\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mnorm, (\u001B[38;5;28mself\u001B[39m,), \u001B[38;5;28mself\u001B[39m, p\u001B[38;5;241m=\u001B[39mp, dim\u001B[38;5;241m=\u001B[39mdim, keepdim\u001B[38;5;241m=\u001B[39mkeepdim, dtype\u001B[38;5;241m=\u001B[39mdtype\n\u001B[1;32m    764\u001B[0m     )\n\u001B[0;32m--> 765\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mnorm(\u001B[38;5;28mself\u001B[39m, p, dim, keepdim, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "File \u001B[0;32m~/miniconda3/envs/default_env/lib/python3.11/site-packages/torch/functional.py:1631\u001B[0m, in \u001B[0;36mnorm\u001B[0;34m(input, p, dim, keepdim, out, dtype)\u001B[0m\n\u001B[1;32m   1629\u001B[0m _p \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2.0\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m p \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m p\n\u001B[1;32m   1630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1631\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mvector_norm(\u001B[38;5;28minput\u001B[39m, _p, _dim, keepdim, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m   1632\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1633\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mvector_norm(\u001B[38;5;28minput\u001B[39m, _p, _dim, keepdim, dtype\u001B[38;5;241m=\u001B[39mdtype, out\u001B[38;5;241m=\u001B[39mout)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: linalg.vector_norm: Expected a floating point or complex tensor as input. Got Byte"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T12:05:17.440869Z",
     "start_time": "2024-09-03T12:05:17.437032Z"
    }
   },
   "cell_type": "code",
   "source": "binary_embeddings",
   "id": "55331c2f02e1081c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  29, 255, ..., 147, 241, 255],\n",
       "       [ 64,   0,   0, ..., 255, 255,   0],\n",
       "       [255, 255, 183, ...,   0,   0, 182]], dtype=uint8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cdfb30649cf2e077"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
