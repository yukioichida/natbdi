{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-18T22:43:40.864967Z",
     "start_time": "2024-08-18T22:43:38.838745Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from sources.cl_nli.model import SimCSE\n",
    "from sources.fallback_policy.model import QNetwork\n",
    "from sources.scienceworld import parse_beliefs\n",
    "\n",
    "from sources.fallback_policy.replay import ReplayMemory, Transition"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Reading goldpath trajectories",
   "id": "43b359c162afc26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T22:43:40.871745Z",
     "start_time": "2024-08-18T22:43:40.866344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "goldpath_file = \"/opt/data/scienceworld-goldpaths/goldsequences-0.json\"\n",
    "\n",
    "with open(goldpath_file) as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "json_data = json_data['0']\n",
    "\n",
    "json_data.keys()"
   ],
   "id": "665684dbb9595f29",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['taskIdx', 'taskName', 'goldActionSequences'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T22:43:44.075633Z",
     "start_time": "2024-08-18T22:43:40.872801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ckpt = \"/opt/models/simcse_default/version_0/v0-epoch=4-step=18304-val_nli_loss=0.658-train_loss=0.551.ckpt\"\n",
    "\n",
    "model: SimCSE = SimCSE.load_from_checkpoint(ckpt).eval()\n",
    "hf_model_name = model.hparams['hf_model_name']\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model_name)"
   ],
   "id": "9e98b425dbabce41",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ichida/miniconda3/envs/default_env/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create memory buffer",
   "id": "b8bd533771827901"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T22:43:44.081001Z",
     "start_time": "2024-08-18T22:43:44.077437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode(texts: list[str], max_size: int = 25, include_cls: bool = True) -> torch.Tensor:\n",
    "    if include_cls:\n",
    "        cls_token = tokenizer.cls_token\n",
    "        texts = [cls_token] + texts\n",
    "    pad_size = max_size - len(texts)\n",
    "    padding = [tokenizer.pad_token for _ in range(pad_size)]\n",
    "    texts = texts + padding\n",
    "    tokenized_text = tokenizer(texts, padding='longest', truncation=True,\n",
    "                               return_tensors='pt').to(model.device)\n",
    "    embeddings = model.encode(tokenized_text).detach().unsqueeze(0)  # batch axis\n",
    "    return embeddings\n",
    "\n"
   ],
   "id": "7c004c5d2c3bf248",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T22:43:48.019310Z",
     "start_time": "2024-08-18T22:43:44.082086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gold_sequence = json_data['goldActionSequences'][0]['path']\n",
    "\n",
    "goal = json_data['goldActionSequences'][0]['taskDescription'].split('.')[0]\n",
    "variation_idx = json_data['goldActionSequences'][0]['variationIdx']\n",
    "print(f\"Goal: {goal} - variation {variation_idx}\")\n",
    "\n",
    "all_lens = []\n",
    "\n",
    "trajectories_bdi = []\n",
    "\n",
    "memory_buffer = ReplayMemory(1000)\n",
    "\n",
    "last_reward = 0\n",
    "for i, trajectory in enumerate(gold_sequence):\n",
    "    observation = trajectory['observation']\n",
    "    look_around = trajectory['freelook']\n",
    "    inventory = trajectory['inventory']\n",
    "    belief_base = parse_beliefs(observation=observation, look=look_around, inventory=inventory)\n",
    "\n",
    "    next_trajectory = gold_sequence[i + 1]\n",
    "    next_belief_base = parse_beliefs(observation=next_trajectory['observation'],\n",
    "                                     look=next_trajectory['freelook'],\n",
    "                                     inventory=next_trajectory['inventory'])\n",
    "\n",
    "    reward = float(trajectory['score']) - last_reward\n",
    "    last_reward = float(trajectory['score'])\n",
    "    is_done = trajectory['isCompleted']\n",
    "    if is_done == 'true':\n",
    "        next_state = \"\"\n",
    "        print(\"finish\")\n",
    "        break\n",
    "        # ou break de repente aqui\n",
    "\n",
    "    memory_buffer.push(\n",
    "            Transition(\n",
    "                    belief_base=encode(belief_base + [goal]),\n",
    "                    num_beliefs=len(belief_base) + 1,  # including goal\n",
    "                    action=encode([trajectory['action']], max_size=1, include_cls=False),\n",
    "                    next_belief_base=encode(next_belief_base + [goal]),\n",
    "                    num_next_beliefs=len(next_belief_base) + 1,\n",
    "                    next_action=encode([next_trajectory['action']], max_size=1, include_cls=False),\n",
    "                    reward=reward,\n",
    "                    done=True if is_done == 'true' else False\n",
    "            )\n",
    "    )\n",
    "\n",
    "    #print(f\"Step {i} - reward: {reward:.3f} - is_done: {is_done}  - action: {trajectory['action']}\")"
   ],
   "id": "585ca7affeca7d46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal: Your task is to boil water - variation 0\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train q-network using annotated trajectories",
   "id": "c326011ec0529219"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T22:43:48.045692Z",
     "start_time": "2024-08-18T22:43:48.020689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sources.fallback_policy.model import SimpleQNetwork\n",
    "\n",
    "#network = QNetwork(768, 768, n_blocks=3)\n",
    "network = SimpleQNetwork(768, 768, 5)\n",
    "network = network.to('cuda')\n",
    "network.train()\n",
    "\n",
    "num_parameters = sum(p.numel() for p in network.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters: {num_parameters}\")\n",
    "network"
   ],
   "id": "19ec2323278a0b35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 4133376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleQNetwork(\n",
       "  (belief_base_encoder): ModuleList(\n",
       "    (0-4): 5 x Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (hidden): Linear(in_features=1536, out_features=768, bias=False)\n",
       "  (q_value_layer): Linear(in_features=768, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T22:43:53.505276Z",
     "start_time": "2024-08-18T22:43:48.046629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# q-learning \n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "optimizer = torch.optim.Adam(network.parameters())\n",
    "\n",
    "\n",
    "def contrastive_loss(belief_base_emb, num_belief_emb, action_emb):\n",
    "    batch_size, _, _ = belief_base_emb.size()\n",
    "\n",
    "    belief_q_values = []\n",
    "    for belief_idx in range(32):\n",
    "        c_belief_base = belief_base_emb[belief_idx, :, :].unsqueeze(0)\n",
    "        c_belief_base = c_belief_base.repeat(batch_size, 1, 1)\n",
    "        q_values = network(belief_base=c_belief_base,\n",
    "                           belief_base_sizes=[num_belief_emb[belief_idx] for _ in range(batch_size)],\n",
    "                           action_tensors=action_emb)\n",
    "        belief_q_values.append(q_values.squeeze(0))\n",
    "    \n",
    "    all_q_values = torch.cat(belief_q_values, dim=-1)\n",
    "    #labels = torch.arange(batch_size).float().to('cuda')\n",
    "    labels = torch.zeros_like(all_q_values).to('cuda')\n",
    "    labels = labels.fill_diagonal_(10)\n",
    "    all_q_values = all_q_values.view(batch_size*batch_size, 1)\n",
    "    labels = labels.view(batch_size*batch_size, 1)\n",
    "    #print(all_q_values[:batch_size])\n",
    "    #print(labels[:batch_size])\n",
    "    return F.mse_loss(all_q_values, labels)\n",
    "    \n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    batch = memory_buffer.sample(BATCH_SIZE)\n",
    "    belief_base_emb = torch.cat([b.belief_base for b in batch], dim=0)\n",
    "    batch_size, _, belief_dim = belief_base_emb.size()\n",
    "    num_belief_emb = [b.num_beliefs for b in batch]\n",
    "    actions = torch.cat([b.action for b in batch]).squeeze(1)  # removing mid axis [bs, ?, a_dim] -> [bs, a_dim]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = contrastive_loss(belief_base_emb, num_belief_emb, actions)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"epoch {epoch} - loss {loss.item(): .4f}\")\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #break\n",
    "    #nn.utils.clip_grad_norm_(network.parameters(), 1.)\n",
    "\n"
   ],
   "id": "76073dcf3fff52a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 - loss  3.1131\n",
      "epoch 10 - loss  3.0232\n",
      "epoch 20 - loss  3.0004\n",
      "epoch 30 - loss  2.9661\n",
      "epoch 40 - loss  2.9800\n",
      "epoch 50 - loss  2.9573\n",
      "epoch 60 - loss  3.0023\n",
      "epoch 70 - loss  2.9714\n",
      "epoch 80 - loss  2.9581\n",
      "epoch 90 - loss  2.9841\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T22:44:05.540842Z",
     "start_time": "2024-08-18T22:44:05.534340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "turn = 1\n",
    "print(gold_sequence[turn]['action'])\n",
    "annotated_belief_base = parse_beliefs(observation=gold_sequence[turn - 1]['observation'],\n",
    "                                      look=gold_sequence[turn - 1]['freelook'],\n",
    "                                      inventory=gold_sequence[turn - 1]['inventory']) + [goal]\n",
    "#annotated_belief_base = ['This room is called the kitchen', 'You see a anchor', 'you see a metal pot'] + [goal]\n",
    "print(len(annotated_belief_base))\n",
    "annotated_belief_base"
   ],
   "id": "4d8219195d3e7a1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open door to kitchen\n",
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['This room is called the hallway.',\n",
       " 'You see a picture',\n",
       " 'You see a substance called air',\n",
       " 'You see the agent',\n",
       " 'A door to the green house (that is open)',\n",
       " 'A door to the living room (that is open)',\n",
       " 'A door to the art studio (that is open)',\n",
       " 'A door to the kitchen (that is open)',\n",
       " 'A door to the bedroom (that is open)',\n",
       " 'A door to the workshop (that is open)',\n",
       " 'In your inventory, you see: an orange ',\n",
       " '',\n",
       " 'Your task is to boil water']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T22:44:06.991259Z",
     "start_time": "2024-08-18T22:44:06.953984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoded_belief_base = encode(annotated_belief_base, max_size=len(annotated_belief_base) + 1)\n",
    "print(encoded_belief_base.size())\n",
    "#candidate_actions = info['valid']\n",
    "candidate_actions = ['focus on bedroom door', 'open door to kitchen', 'go to kitchen', 'pick up thermometer']\n",
    "encoded_actions = encode(candidate_actions, include_cls=False, max_size=len(candidate_actions))\n",
    "encoded_actions = encoded_actions.squeeze(0)\n",
    "print(encoded_actions.size())\n",
    "num_actions, action_dim = encoded_actions.size()\n",
    "repeat_encoded_belief_base = encoded_belief_base.repeat(num_actions, 1, 1)\n",
    "q_values = network(belief_base=repeat_encoded_belief_base,\n",
    "                   belief_base_sizes=[len(annotated_belief_base) + 1 for _ in range(num_actions)],\n",
    "                   action_tensors=encoded_actions)\n",
    "print(q_values.size())\n",
    "\n",
    "\n",
    "values, idxs = torch.sort(q_values.squeeze(1), descending=True)\n",
    "for i, idx in enumerate(idxs[:5]):\n",
    "    print(f\"act {candidate_actions[idx]} - q_value: {values[i]:.3f}\")"
   ],
   "id": "ce878dffffd298de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 1])\n",
      "act go to kitchen - q_value: 0.715\n",
      "act open door to kitchen - q_value: 0.487\n",
      "act focus on bedroom door - q_value: 0.097\n",
      "act pick up thermometer - q_value: -0.125\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluating Q-network in scienceworld environment",
   "id": "a72e5f68d324132d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
