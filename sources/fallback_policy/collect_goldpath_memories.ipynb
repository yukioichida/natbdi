{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:03:15.583062Z",
     "start_time": "2024-08-17T15:03:13.742710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from sources.cl_nli.model import SimCSE\n",
    "from sources.fallback_policy.model import QNetwork\n",
    "from sources.scienceworld import parse_beliefs"
   ],
   "id": "f7654e6db60d5017",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-17T15:03:15.589727Z",
     "start_time": "2024-08-17T15:03:15.584282Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "goldpath_file = \"/opt/data/scienceworld-goldpaths/goldsequences-0.json\"\n",
    "\n",
    "with open(goldpath_file) as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "json_data = json_data['0']\n",
    "\n",
    "json_data.keys()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['taskIdx', 'taskName', 'goldActionSequences'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:03:15.629834Z",
     "start_time": "2024-08-17T15:03:15.590832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trajectories = json_data['goldActionSequences'][0]['path']\n",
    "goal = json_data['goldActionSequences'][0]['taskDescription'].split('.')[0]\n",
    "\n",
    "all_lens = []\n",
    "\n",
    "trajectories_bdi = []\n",
    "\n",
    "last_reward = 0\n",
    "for i, trajectory in enumerate(trajectories):\n",
    "    observation = trajectory['observation']\n",
    "    look_around = trajectory['freelook']\n",
    "    inventory = trajectory['inventory']\n",
    "\n",
    "    belief_base = parse_beliefs(observation=observation, look=look_around, inventory=inventory)\n",
    "\n",
    "    next_trajectory = trajectories[i + 1]\n",
    "    next_belief_base = parse_beliefs(observation=next_trajectory['observation'],\n",
    "                                     look=next_trajectory['freelook'],\n",
    "                                     inventory=next_trajectory['inventory'])\n",
    "\n",
    "    all_lens.append(len(belief_base))\n",
    "    action = trajectory['action']\n",
    "    reward = float(trajectory['score']) - last_reward\n",
    "    last_reward = float(trajectory['score'])\n",
    "    is_done = trajectory['isCompleted']\n",
    "    if is_done == 'true':\n",
    "        next_state = \"\"\n",
    "        print(\"finish\")\n",
    "        break\n",
    "        # ou break de repente aqui\n",
    "\n",
    "    trajectories_bdi.append({\n",
    "            'belief_base': belief_base + [goal],\n",
    "            'action': action,\n",
    "            'next_belief_base': next_belief_base + [goal],\n",
    "            'next_action': next_trajectory['action'],\n",
    "            'reward': reward\n",
    "    })\n",
    "\n",
    "    print(f\"Step {i} - reward: {reward:.3f} - is_done: {is_done} - score {float(trajectory['score']):.3f}\")"
   ],
   "id": "3f6117421956ce75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 - reward: 0.000 - is_done: false - score 0.000\n",
      "Step 1 - reward: 0.000 - is_done: false - score 0.000\n",
      "Step 2 - reward: 0.000 - is_done: false - score 0.000\n",
      "Step 3 - reward: 0.000 - is_done: false - score 0.000\n",
      "Step 4 - reward: 0.000 - is_done: false - score 0.000\n",
      "Step 5 - reward: 0.000 - is_done: false - score 0.000\n",
      "Step 6 - reward: 0.000 - is_done: false - score 0.000\n",
      "Step 7 - reward: 0.000 - is_done: false - score 0.000\n",
      "Step 8 - reward: 0.000 - is_done: false - score 0.000\n",
      "Step 9 - reward: 0.033 - is_done: false - score 0.033\n",
      "Step 10 - reward: 0.000 - is_done: false - score 0.033\n",
      "Step 11 - reward: 0.000 - is_done: false - score 0.033\n",
      "Step 12 - reward: 0.667 - is_done: false - score 0.700\n",
      "Step 13 - reward: 0.000 - is_done: false - score 0.700\n",
      "Step 14 - reward: 0.000 - is_done: false - score 0.700\n",
      "Step 15 - reward: 0.017 - is_done: false - score 0.717\n",
      "Step 16 - reward: 0.017 - is_done: false - score 0.733\n",
      "Step 17 - reward: 0.000 - is_done: false - score 0.733\n",
      "Step 18 - reward: 0.000 - is_done: false - score 0.733\n",
      "Step 19 - reward: 0.000 - is_done: false - score 0.733\n",
      "Step 20 - reward: 0.000 - is_done: false - score 0.733\n",
      "Step 21 - reward: 0.000 - is_done: false - score 0.733\n",
      "Step 22 - reward: 0.017 - is_done: false - score 0.750\n",
      "Step 23 - reward: 0.000 - is_done: false - score 0.750\n",
      "Step 24 - reward: 0.000 - is_done: false - score 0.750\n",
      "Step 25 - reward: 0.000 - is_done: false - score 0.750\n",
      "Step 26 - reward: 0.000 - is_done: false - score 0.750\n",
      "Step 27 - reward: 0.000 - is_done: false - score 0.750\n",
      "Step 28 - reward: 0.000 - is_done: false - score 0.750\n",
      "Step 29 - reward: 0.000 - is_done: false - score 0.750\n",
      "Step 30 - reward: 0.000 - is_done: false - score 0.750\n",
      "Step 31 - reward: 0.000 - is_done: false - score 0.750\n",
      "Step 32 - reward: 0.000 - is_done: false - score 0.750\n",
      "Step 33 - reward: 0.000 - is_done: false - score 0.750\n",
      "Step 34 - reward: 0.000 - is_done: false - score 0.750\n",
      "Step 35 - reward: 0.000 - is_done: false - score 0.750\n",
      "finish\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sampling a single trajectory",
   "id": "37b95177da463cdb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:03:15.636149Z",
     "start_time": "2024-08-17T15:03:15.631400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"{len(trajectories_bdi[12]['belief_base'])} - {len(trajectories_bdi[12]['next_belief_base'])}\")\n",
    "trajectories_bdi[12]"
   ],
   "id": "9d17f76c5a2e3e5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 - 23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'belief_base': ['This room is called the kitchen.',\n",
       "  'You see a substance called soap',\n",
       "  'You see a painting',\n",
       "  'You see a counter. On the counter is: a bowl (containing a banana, a potato, a red apple, an orange), a drawer.',\n",
       "  'You see a sink, which is turned off. In the sink is: nothing.',\n",
       "  'You see a table. On the table is: a glass cup (containing nothing).',\n",
       "  'You see a chair. On the chair is: nothing.',\n",
       "  'You see a freezer. The freezer door is closed.',\n",
       "  'You see a lighter',\n",
       "  'You see a stopwatch, which is deactivated.',\n",
       "  'You see a fridge. The fridge door is closed.',\n",
       "  'You see a substance called air',\n",
       "  'You see a cupboard. The cupboard door is open. In the cupboard is: a tin cup (containing nothing), a ceramic cup (containing nothing), a drawer.',\n",
       "  'You see a oven, which is turned off. The oven door is closed.',\n",
       "  'You see a glass jar (containing a substance called sodium chloride)',\n",
       "  'You see the agent',\n",
       "  'You see a stove, which is turned off. On the stove is: nothing.',\n",
       "  'A door to the outside (that is open)',\n",
       "  'A door to the bathroom (that is open)',\n",
       "  'A door to the hallway (that is open)',\n",
       "  'In your inventory, you see: a thermometer, currently reading a temperature of 10 degrees celsius a metal pot (containing a substance called water) an orange ',\n",
       "  'You focus on the water.',\n",
       "  'Your task is to boil water'],\n",
       " 'action': 'focus on substance in metal pot',\n",
       " 'next_belief_base': ['This room is called the kitchen.',\n",
       "  'You see a substance called soap',\n",
       "  'You see a painting',\n",
       "  'You see a counter. On the counter is: a bowl (containing a banana, a potato, a red apple, an orange), a drawer.',\n",
       "  'You see a sink, which is turned off. In the sink is: nothing.',\n",
       "  'You see a table. On the table is: a glass cup (containing nothing).',\n",
       "  'You see a chair. On the chair is: nothing.',\n",
       "  'You see a freezer. The freezer door is closed.',\n",
       "  'You see a lighter',\n",
       "  'You see a stopwatch, which is deactivated.',\n",
       "  'You see a fridge. The fridge door is closed.',\n",
       "  'You see a substance called air',\n",
       "  'You see a cupboard. The cupboard door is open. In the cupboard is: a tin cup (containing nothing), a ceramic cup (containing nothing), a drawer.',\n",
       "  'You see a oven, which is turned off. The oven door is closed.',\n",
       "  'You see a glass jar (containing a substance called sodium chloride)',\n",
       "  'You see the agent',\n",
       "  'You see a stove, which is turned off. On the stove is: nothing.',\n",
       "  'A door to the outside (that is open)',\n",
       "  'A door to the bathroom (that is open)',\n",
       "  'A door to the hallway (that is open)',\n",
       "  'In your inventory, you see: a thermometer, currently reading a temperature of 10 degrees celsius a metal pot (containing a substance called water) an orange ',\n",
       "  \"You can't move something into itself.\",\n",
       "  'Your task is to boil water'],\n",
       " 'next_action': 'pour metal pot into metal pot',\n",
       " 'reward': 0.6666666666666666}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:03:19.187746Z",
     "start_time": "2024-08-17T15:03:15.637170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ckpt = \"/opt/models/simcse_default/version_0/v0-epoch=4-step=18304-val_nli_loss=0.658-train_loss=0.551.ckpt\"\n",
    "\n",
    "model: SimCSE = SimCSE.load_from_checkpoint(ckpt).eval()\n",
    "hf_model_name = model.hparams['hf_model_name']\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model_name)"
   ],
   "id": "673da87138e4fd4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ichida/miniconda3/envs/default_env/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prepare tensors\n",
    "- Embeds all belief trajectory and actions as well"
   ],
   "id": "26377df3d501557d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:03:19.192328Z",
     "start_time": "2024-08-17T15:03:19.188869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_trajectory = trajectories_bdi[12]\n",
    "\n",
    "belief_base = example_trajectory['belief_base']\n",
    "next_belief_base = example_trajectory['next_belief_base']\n",
    "\n",
    "belief_intersection = [b for b in belief_base if b not in next_belief_base]\n",
    "belief_intersection"
   ],
   "id": "fe02ba597638a4cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You focus on the water.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:03:20.072518Z",
     "start_time": "2024-08-17T15:03:19.193441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def encode(texts: list[str]):\n",
    "    tokenized_text = tokenizer(texts, padding='longest', truncation=True,\n",
    "                               return_tensors='pt').to(model.device)\n",
    "    return model.encode(tokenized_text).detach()\n",
    "\n",
    "\n",
    "belief_base_emb = encode(example_trajectory['belief_base']).unsqueeze(0)\n",
    "next_belief_base_emb = encode(example_trajectory['next_belief_base']).unsqueeze(0)\n",
    "action_emb = encode(example_trajectory['action'])\n",
    "next_action_emb = encode(example_trajectory['next_action'])\n",
    "\n",
    "fake_action_emb = encode([\"go to kitchen\"])\n",
    "fake_next_belief_base_emb = torch.randn(next_belief_base_emb.size()).to('cuda')\n",
    "\n",
    "transition_a = (belief_base_emb, action_emb, next_belief_base_emb, next_action_emb, example_trajectory['reward'])\n",
    "transition_b = (belief_base_emb, fake_action_emb, fake_next_belief_base_emb, fake_action_emb, 0)\n",
    "\n",
    "batch_belief_base = torch.cat([transition_a[0], transition_b[0]]).to('cuda')\n",
    "batch_action = torch.cat([transition_a[1], transition_b[1]]).to('cuda')\n",
    "batch_next_belief_base = torch.cat([transition_a[2], transition_b[2]]).to('cuda')\n",
    "batch_next_actions = torch.cat([transition_a[3], transition_b[3]]).to('cuda')\n",
    "batch_reward = torch.tensor([transition_a[4], transition_b[4]], dtype=torch.float).to('cuda')\n",
    "batch_reward"
   ],
   "id": "ea6fa51b70bc6474",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6667, 0.0000], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:03:20.077208Z",
     "start_time": "2024-08-17T15:03:20.073538Z"
    }
   },
   "cell_type": "code",
   "source": "belief_base_emb.size()",
   "id": "bc5eebe2348efafd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 23, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:03:20.116093Z",
     "start_time": "2024-08-17T15:03:20.078216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size, num_beliefs, embedding_dim = belief_base_emb.size()\n",
    "\n",
    "network = QNetwork(embedding_dim, embedding_dim, embedding_dim, n_blocks=2)\n",
    "network = network.to('cuda')\n",
    "network"
   ],
   "id": "3e471656b9a35a6d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QNetwork(\n",
       "  (belief_base_encoder): BeliefBaseEncoder(\n",
       "    (blocks): ModuleList(\n",
       "      (0-1): 2 x BeliefTransformerBlock(\n",
       "        (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (layer_norm_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (qkv_proj_layer): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (mlp): PositionWiseFF(\n",
       "          (c_fc): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layer_norm_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (hidden): Linear(in_features=1536, out_features=768, bias=False)\n",
       "  (q_value_layer): Linear(in_features=768, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:23:14.204774Z",
     "start_time": "2024-08-17T15:23:13.606238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# q-learning \n",
    "GAMMA = 0.99\n",
    "\n",
    "num_parameters = sum(p.numel() for p in network.parameters() if p.requires_grad)\n",
    "print(f\"Number of parameters: {num_parameters}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    # Q(s', a')\n",
    "    next_q_values = network(belief_base=batch_next_belief_base,\n",
    "                            belief_base_sizes=[num_beliefs],\n",
    "                            action_tensors=batch_next_actions)\n",
    "    best_next_q_values = next_q_values.squeeze(-1)\n",
    "    targets = batch_reward + (GAMMA * best_next_q_values)\n",
    "\n",
    "    # Q(s, a)\n",
    "    q_values = network(belief_base=batch_belief_base, belief_base_sizes=[num_beliefs], action_tensors=batch_action)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"[{epoch}] q-values {q_values.squeeze(-1)}, targets {targets.squeeze(-1)}\")\n",
    "    loss = F.smooth_l1_loss(q_values.squeeze(-1), targets.detach())\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(network.parameters(), 5.)\n",
    "    optimizer.step()\n",
    "    #break"
   ],
   "id": "637e39eab06979f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 7081728\n",
      "[0] q-values tensor([ 2.8172, -0.9102], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([ 2.8176, -0.9106], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[10] q-values tensor([ 2.8851, -0.8148], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([ 2.8848, -0.8501], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[20] q-values tensor([ 3.0545, -0.8553], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([ 3.0526, -0.8607], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[30] q-values tensor([ 3.1043, -0.8943], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([ 3.0981, -0.8743], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[40] q-values tensor([ 3.0852, -0.9227], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([ 3.0814, -0.8810], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[50] q-values tensor([ 3.0745, -0.9214], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([ 3.0773, -0.8736], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[60] q-values tensor([ 3.0387, -0.9046], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([ 3.0504, -0.8566], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[70] q-values tensor([ 2.9803, -0.9304], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([ 2.9934, -0.8599], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[80] q-values tensor([ 3.1865, -0.9198], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([ 3.1683, -0.8609], device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
      "[90] q-values tensor([ 3.1568, -0.7097], device='cuda:0', grad_fn=<SqueezeBackward1>), targets tensor([ 3.1436, -0.7372], device='cuda:0', grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:15:09.249924Z",
     "start_time": "2024-08-17T15:15:09.235291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(next_q_values)#.max(dim=-1),\n",
    "next_q_values.size(), batch_reward.unsqueeze(1).size(), targets.size(), q_values.size(), best_next_q_values.size()"
   ],
   "id": "dc26420513ba71f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4348],\n",
      "        [0.2647]], device='cuda:0', grad_fn=<MmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1]),\n",
       " torch.Size([2, 1]),\n",
       " torch.Size([2]),\n",
       " torch.Size([2, 1]),\n",
       " torch.Size([2]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:17:27.330985Z",
     "start_time": "2024-08-17T15:17:27.325909Z"
    }
   },
   "cell_type": "code",
   "source": "next_q_values.squeeze(-1)",
   "id": "4748f0f954364104",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4348, 0.2647], device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:06:02.500984Z",
     "start_time": "2024-08-17T15:06:02.486506Z"
    }
   },
   "cell_type": "code",
   "source": "torch.nn.CosineSimilarity(dim=-1)(belief_base_emb.squeeze(0), next_belief_base_emb.squeeze(0)).mean()",
   "id": "8f9e0989bdbf0604",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9630, device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:03:20.236365Z",
     "start_time": "2024-08-17T15:03:20.233164Z"
    }
   },
   "cell_type": "code",
   "source": "example_trajectory['next_action'], example_trajectory['action']",
   "id": "f32715df112c54a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pour metal pot into metal pot', 'focus on substance in metal pot')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T15:03:20.239170Z",
     "start_time": "2024-08-17T15:03:20.237387Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cc0f773c8b4e16e",
   "outputs": [],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
